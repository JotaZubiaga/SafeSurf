# SafeSurf â€“ Proyecto de ML para la detecciÃ³n de Riesgos en URLs 
**Proyecto de ML para analizar la seguridad de una URL introducida.**

Este proyecto tiene como objetivo desarrollar un modelo de aprendizaje automÃ¡tico capaz de identificar URLs sospechosas basÃ¡ndose en sus caracterÃ­sticas estructurales. En esta primera versiÃ³n, utiliza un enfoque basado en la extracciÃ³n de features directamente desde la URL sin necesidad de acceder a la pÃ¡gina web.

## ğŸ“Œ CaracterÃ­sticas Principales
- **ExtracciÃ³n AutomÃ¡tica de CaracterÃ­sticas:** Se analizan las URL ingresadas en Streamlit para extraer informaciÃ³n relevante como la longitud, cantidad de guiones, si contiene HTTPS, entre otros.
- **ComparaciÃ³n de Modelos:** Se han probado distintos algoritmos de clasificaciÃ³n como RegresiÃ³n LogÃ­stica, Random Forest, Support Vector Machines (SVM), K-Nearest Neighbors (KNN) y Ã¡rboles de decisiÃ³n.
- **OptimizaciÃ³n con GridSearchCV:** Se han utilizado tÃ©cnicas de bÃºsqueda de hiperparÃ¡metros para mejorar la precisiÃ³n del modelo.
- **Interfaz en Streamlit:** Permite al usuario ingresar una URL y obtener una evaluaciÃ³n en tiempo real sobre su potencial de ser peligrosa.

## ğŸ“Š Dataset y Variables Utilizadas
El conjunto de datos contiene diversas variables que describen la estructura de las URLs. Algunas de las mÃ¡s relevantes incluyen:

### ğŸ”— Variables relacionadas con la estructura de la URL:
- **NumDots:** NÃºmero de puntos en la URL.
- **NumDash:** NÃºmero de guiones en la URL.
- **NumDashInHostname:** NÃºmero de guiones en el hostname.
- **UrlLength:** Longitud total de la URL.
- **NumQueryComponents:** NÃºmero de componentes en la consulta de la URL.
- **IpAddress:** Si la URL contiene una direcciÃ³n IP en lugar de un dominio.
- **DomainInSubdomains:** Si el dominio principal aparece en los subdominios.
- **DomainInPaths:** Si el dominio aparece en la ruta de la URL.
- **HostnameLength:** Longitud del hostname.
- **PathLevel:** Profundidad del path en la URL.

### ğŸ” Variables relacionadas con el contenido de la pÃ¡gina:
- **NumSensitiveWords:** Cantidad de palabras clave como "login", "bank", "password" en la URL.
- **IframeOrFrame:** Si la pÃ¡gina usa iframes para ocultar contenido.
- **InsecureForms:** Presencia de formularios inseguros.
- **PctExtHyperlinks:** Porcentaje de enlaces externos en la pÃ¡gina.
- **FakeLinkInStatusBar:** Uso de enlaces falsos en la barra de estado del navegador.

## ğŸš€ Modelos de Machine Learning Utilizados
Para la clasificaciÃ³n de URLs, se probaron diversos modelos:

1. **Random Forest**
   - NÂº de estimadores (n_estimators)= `[50, 100, 200]`
   - Profundidad maxima (max_depth)= `[20, 30]`
   - Minima division en samples (min_samples_split) = `[2, 5, 10]`
   - Minima division en hojas (min_samples_leaf) = `[1, 2, 4]`

2. **RegresiÃ³n LogÃ­stica**
   - Solver: `liblinear`, `lbfgs`
   - PenalizaciÃ³n: `l1`, `l2`
   - RegularizaciÃ³n: `C = [0.1, 1, 10]`

3. **Support Vector Machines (SVM)**
   - `C = [0.001, 0.5, 1, 5, 10, 100]`
   - `kernel = ['linear', 'rbf']`
   - `gamma = ['scale', 'auto']`

4. **K-Nearest Neighbors (KNN)**
   - `n_neighbors = [3, 5, 7]`
   - `weights = ['uniform', 'distance']`

5. **Decision Tree**
   - `max_depth = [None, 10, 20]`
   - `min_samples_split = [2, 5]`
   - `min_samples_leaf = [1, 2, 4]`

Se utilizÃ³ `GridSearchCV` para encontrar la mejor combinaciÃ³n de hiperparÃ¡metros y mejorar la precisiÃ³n del modelo.

## ğŸ“ˆ Resultados y Mejor Modelo
Tras la comparaciÃ³n de modelos, el mejor rendimiento se obtuvo con **Random Forest** utilizando los siguientes hiperparÃ¡metros:

- `max_depth=20`
- `n_estimators=50`
- `min_samples_leaf=4`
- `bootstrap=True`
- `min_samples_split=2`

## ğŸ–¥ï¸ ImplementaciÃ³n en Streamlit
La aplicaciÃ³n en **Streamlit** permite al usuario ingresar una URL y obtener una predicciÃ³n en tiempo real sobre su seguridad.

### Pasos para ejecutar la aplicaciÃ³n:
1. Instalar dependencias:
   ```bash
   pip install -r requirements.txt
   ```
2. Ejecutar la aplicaciÃ³n:
   ```bash
   streamlit run app.py
   ```
3. Introducir la URL en el campo de entrada y recibir el resultado de la evaluaciÃ³n.

## ğŸ“‚ Estructura del Proyecto
```
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ Phishing_Legitimate_full.csv  # Dataset original
â”œâ”€â”€ models
â”‚   â”œâ”€â”€ phishing_rf_model.pkl  # Modelo entrenado
â”œâ”€â”€ notebooks
â”‚   â”œâ”€â”€ Exploratory_Analysis.ipynb  # AnÃ¡lisis exploratorio
â”œâ”€â”€ app.py  # AplicaciÃ³n Streamlit
â”œâ”€â”€ requirements.txt  # Dependencias del proyecto
â”œâ”€â”€ README.md  # DocumentaciÃ³n
```

## ğŸ“Œ Conclusiones
- Se logrÃ³ desarrollar un modelo de clasificaciÃ³n de URLs de phishing con una alta precisiÃ³n.
- Se utilizÃ³ **Feature Engineering** para extraer informaciÃ³n directamente desde la URL sin necesidad de acceder a la pÃ¡gina.
- Se optimizÃ³ el modelo con **GridSearchCV** para obtener los mejores hiperparÃ¡metros.
- Se implementÃ³ una interfaz sencilla en **Streamlit** para evaluar URLs en tiempo real.

Este proyecto seguirÃ¡ evolucionando incorporando anÃ¡lisis mÃ¡s avanzados como el uso de **Redes Neuronales** o **Modelos Basados en Transformers** para detecciÃ³n de phishing.

---
ğŸ“Œ **Autor:** Juan Zubiaga Delclaux  
ğŸ“§ **Contacto:** https://github.com/JZubiaga13

